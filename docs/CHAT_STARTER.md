# üöÄ Chat Starter ‚Äî roboflow-counter

**Nutze diesen Textblock immer, wenn du einen neuen Chat beginnst.**
Damit die AI sofort im richtigen Projektkontext arbeitet (laut AI_Playbook).

---

## üëá Starttext in neuem Chat einf√ºgen

Projekt: `roboflow-counter`  
Repository: [https://github.com/miguellcostillia/roboflow-counter](https://github.com/miguellcostillia/roboflow-counter)

Bitte:

- Repository laden & internen Projektkontext initialisieren  
- `docs/AI_Playbook.md` befolgen (Kommunikations- & Formatregeln)  
- `docs/PROJECT_STATE.md` pr√ºfen (aktueller Entwicklungsstand)  
- `docs/CHANGELOG.md` ber√ºcksichtigen  
- `docs/ERROR_LOG.md` & `docs/SUCCESS_LOG.md` beachten (letzter Teststatus)  
- `docs/SESSION_START.md` wird als Einstiegspunkt genutzt  
- Nur 1 aktiver Branch laut Playbook: **main**

---

### üß© Projektumgebung

```bash
cd ~/projects/roboflow-counter
source .venv/bin/activate
```

**Python:** 3.12  
**GPU:** NVIDIA RTX A4000  
**CUDA:** 12.9  
**OpenCV:** 4.10 (mit CUDA/DNN)  
**MediaMTX:** aktiv auf Port 8554  
**Hauptdienste:**
- `roboflow-highlight.service` ‚Äî Motion-Highlight Stream  
- `larvacounter-dump-clean.service` ‚Äî Frame-Export + Cleanup  
- `roboflow-tracker.service` *(optional)* ‚Äî IoU-Tracking / Roboflow-Inference  

---

### ‚öôÔ∏è Antwortformat-Regeln

- Kurz und pr√§zise  
- Code nur in **Patch- oder Command-Bl√∂cken**  
- PR-Workflow beibehalten (`feat:`, `fix:`, `docs:` etc.)  
- Entscheidungen gem√§√ü *AI_Playbook.md* treffen  
- Keine Wiederholungen, keine unn√∂tigen Fragen  
- Nur best√§tigte Files/Komponenten aus `main` ber√ºcksichtigen  

---

### üß† Projektkontext aktiv

- Highlight-Pipeline stabil  
- Dump- & Cleanup-System aktiv  
- Tracker integriert (Basisversion, Overlay in Arbeit)  
- GPU-Inferenz getestet (CUDA 12.9 + A4000)  
- Config-System (`config.loader`) und `.env` funktional  

---

Sage **‚Äû‚úÖ ready‚Äú**, wenn Projekt geladen und Kontext aktiv ist.
